{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9921594982078853\n",
      "SVM precision: 0.9743589743589743\n",
      "SVM recall: 0.9457013574660633\n",
      "SVM f1: 0.9598163030998853\n",
      "RF accuracy: 0.9919354838709677\n",
      "RF precision: 0.9634703196347032\n",
      "RF recall: 0.9547511312217195\n",
      "RF f1: 0.959090909090909\n",
      "DT accuracy: 0.9903673835125448\n",
      "DT precision: 0.9586206896551724\n",
      "DT recall: 0.9434389140271493\n",
      "DT f1: 0.9509692132269099\n",
      "LR accuracy: 0.9908154121863799\n",
      "LR precision: 0.971764705882353\n",
      "LR recall: 0.9343891402714932\n",
      "LR f1: 0.9527104959630911\n"
     ]
    }
   ],
   "source": [
    "## Training ML models to predict the label\n",
    "## Using SVM, Random Forest, Decision Tree, Logistic Regression\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "## Get training and testing set\n",
    "dataset = pd.read_csv('./labeled_candidate_set.csv')\n",
    "\n",
    "## Choose some attribute to train the model\n",
    "dataset = dataset[['ltable_invoice_item_id', 'rtable_purchase_order_item_id', 'name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity', 'label']]\n",
    "\n",
    "train = dataset.sample(frac=0.8, random_state=2)\n",
    "test = dataset.drop(train.index)\n",
    "\n",
    "## Create the model\n",
    "SVM = svm.SVC(kernel='rbf')\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "DT = DecisionTreeClassifier()\n",
    "LR = LogisticRegression()\n",
    "\n",
    "## Train the model\n",
    "SVM.fit(train[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']], train['label'])\n",
    "RF.fit(train[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']], train['label'])\n",
    "DT.fit(train[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']], train['label'])\n",
    "LR.fit(train[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']], train['label'])\n",
    "\n",
    "## Test the model\n",
    "SVM_pred = SVM.predict(test[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "RF_pred = RF.predict(test[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "DT_pred = DT.predict(test[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "LR_pred = LR.predict(test[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "print('SVM accuracy:', accuracy_score(test['label'], SVM_pred))\n",
    "print('SVM precision:', precision_score(test['label'], SVM_pred))\n",
    "print('SVM recall:', recall_score(test['label'], SVM_pred))\n",
    "print('SVM f1:', f1_score(test['label'], SVM_pred))\n",
    "\n",
    "print('RF accuracy:', accuracy_score(test['label'], RF_pred))\n",
    "print('RF precision:', precision_score(test['label'], RF_pred))\n",
    "print('RF recall:', recall_score(test['label'], RF_pred))\n",
    "print('RF f1:', f1_score(test['label'], RF_pred))\n",
    "\n",
    "print('DT accuracy:', accuracy_score(test['label'], DT_pred))\n",
    "print('DT precision:', precision_score(test['label'], DT_pred))\n",
    "print('DT recall:', recall_score(test['label'], DT_pred))\n",
    "print('DT f1:', f1_score(test['label'], DT_pred))\n",
    "\n",
    "print('LR accuracy:', accuracy_score(test['label'], LR_pred))\n",
    "print('LR precision:', precision_score(test['label'], LR_pred))\n",
    "print('LR recall:', recall_score(test['label'], LR_pred))\n",
    "print('LR f1:', f1_score(test['label'], LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model using pickle\n",
    "import pickle\n",
    "\n",
    "with open('SVM_model.pkl', 'wb') as f:\n",
    "    pickle.dump(SVM, f)\n",
    "\n",
    "with open('RF_model.pkl', 'wb') as f:\n",
    "    pickle.dump(RF, f)\n",
    "\n",
    "with open('DT_model.pkl', 'wb') as f:\n",
    "    pickle.dump(DT, f)\n",
    "\n",
    "with open('LR_model.pkl', 'wb') as f:\n",
    "    pickle.dump(LR, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169438 3169438\n",
      "SVM accuracy: 0.9965110533791796\n",
      "SVM precision: 0.16312977099236642\n",
      "SVM recall: 0.9574372759856631\n",
      "SVM f1: 0.27876337072788937\n",
      "RF accuracy: 0.9959589050172302\n",
      "RF precision: 0.14657131399545514\n",
      "RF recall: 0.9825268817204301\n",
      "RF f1: 0.25508898452948703\n",
      "DT accuracy: 0.9953707881334167\n",
      "DT precision: 0.13002617178206044\n",
      "DT recall: 0.9793906810035843\n",
      "DT f1: 0.22957361898760767\n",
      "LR accuracy: 0.996800379120841\n",
      "LR precision: 0.17261362695587382\n",
      "LR recall: 0.9341397849462365\n",
      "LR f1: 0.29138424987771644\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "dataset = pd.read_csv('./validate_candidate_set.csv')\n",
    "\n",
    "## Load the model using pickle to predict the label\n",
    "svm_model = pickle.load(open('SVM_model.pkl', 'rb'))\n",
    "rf_model = pickle.load(open('RF_model.pkl', 'rb'))\n",
    "dt_model = pickle.load(open('DT_model.pkl', 'rb'))\n",
    "lr_model = pickle.load(open('LR_model.pkl', 'rb'))\n",
    "\n",
    "## Predict the label\n",
    "testing = pd.read_csv('./candidate_set.csv')\n",
    "\n",
    "print(len(testing), len(dataset))\n",
    "\n",
    "testing = testing[['ltable_invoice_item_id', 'rtable_purchase_order_item_id', 'name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']]\n",
    "svm_predict = svm_model.predict(testing[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "rf_predict = rf_model.predict(testing[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "dt_predict = dt_model.predict(testing[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "lr_predict = lr_model.predict(testing[['name_similarity', 'unit_similarity', 'unit_price_similarity', 'quantity_similarity', 'total_price_before_vat_similarity', 'vat_amount_similarity']])\n",
    "\n",
    "## Evaluate the model\n",
    "print('SVM accuracy:', accuracy_score(dataset['label'], svm_predict))\n",
    "print('SVM precision:', precision_score(dataset['label'], svm_predict))\n",
    "print('SVM recall:', recall_score(dataset['label'], svm_predict))\n",
    "print('SVM f1:', f1_score(dataset['label'], svm_predict))\n",
    "\n",
    "print('RF accuracy:', accuracy_score(dataset['label'], rf_predict))\n",
    "print('RF precision:', precision_score(dataset['label'], rf_predict))\n",
    "print('RF recall:', recall_score(dataset['label'], rf_predict))\n",
    "print('RF f1:', f1_score(dataset['label'], rf_predict))\n",
    "\n",
    "print('DT accuracy:', accuracy_score(dataset['label'], dt_predict))\n",
    "print('DT precision:', precision_score(dataset['label'], dt_predict))\n",
    "print('DT recall:', recall_score(dataset['label'], dt_predict))\n",
    "print('DT f1:', f1_score(dataset['label'], dt_predict))\n",
    "\n",
    "print('LR accuracy:', accuracy_score(dataset['label'], lr_predict))\n",
    "print('LR precision:', precision_score(dataset['label'], lr_predict))\n",
    "print('LR recall:', recall_score(dataset['label'], lr_predict))\n",
    "print('LR f1:', f1_score(dataset['label'], lr_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
